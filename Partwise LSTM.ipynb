{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Niranjan Jangir B21CH021"
      ],
      "metadata": {
        "id": "4CbBTqai_ZbV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing necessary libraries and processing the data, same as the previous question:"
      ],
      "metadata": {
        "id": "KWTIipIb_djU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrFluR3V1OLA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.io import loadmat\n",
        "import matplotlib as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = loadmat(r\"Training_Data_Four_Tanks.mat\")\n",
        "test_data = loadmat(r\"Testing_Data_Four_Tanks.mat\")"
      ],
      "metadata": {
        "id": "BwtLtOx92WiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_input_data = pd.DataFrame(train_data['input_data'],columns = ['v1','v2'])  #input features from the data\n",
        "train_output_data = pd.DataFrame(train_data['output_data'],columns =['h1','h2']) #output i.e. target features\n",
        "train_time_span = pd.DataFrame(train_data['time_span'],columns=['time']) #time span\n",
        "print(train_input_data.shape)\n",
        "print(train_output_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9a5IWfP2Yqx",
        "outputId": "94db34cd-de47-4a29-8ee5-3f78bdc40230"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(90001, 2)\n",
            "(90001, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_input_data = pd.DataFrame(test_data['input_data'],columns = ['v1','v2']) #input features from the data\n",
        "test_output_data = pd.DataFrame(test_data['output_data'],columns =['h1','h2']) #output i.e. target features\n",
        "test_time_span = pd.DataFrame(test_data['time_span'],columns=['time']) #time span\n",
        "print(test_input_data.shape)\n",
        "print(test_output_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMYyhP1c2ck8",
        "outputId": "3dd2cb55-47fc-49db-9f25-b379ff58ac28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60001, 2)\n",
            "(60001, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing the data:"
      ],
      "metadata": {
        "id": "_T_0vheCAOYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#training input data:\n",
        "plt.plot(train_input_data['v1'], label = 'train_input')\n",
        "plt.title(\"training input dataset\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "cw8NL-GHAP-g",
        "outputId": "0896493c-ce3e-424f-b85f-8b53c7a0f3fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#testing input data\n",
        "plt.plot(test_input_data['v1'], label='test_input')\n",
        "plt.title(\"testing input dataset\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "bW3fRt3hAaCH",
        "outputId": "3b1addbe-1054-4e02-eab3-022b17f5761d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  1. As the last row int the input data was [1,1], so droping it from the datasets.\n",
        "  2. Then Splitting the dataset into three parts as per the above visualization"
      ],
      "metadata": {
        "id": "DRJa4fQt_p7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#drop the last rows from training input, training output, testing input and testing output\n",
        "train_input_data = train_input_data.drop(train_input_data.index[-1])\n",
        "train_output_data = train_output_data.drop(train_output_data.index[-1])\n",
        "test_input_data = test_input_data.drop(test_input_data.index[-1])\n",
        "test_output_data = test_output_data.drop(test_output_data.index[-1])\n",
        "\n",
        "#split the dataset into three parts\n",
        "train_df_parts = np.array_split(train_input_data, 3)\n",
        "\n",
        "#assign three different training inputs for their respective operating conditions\n",
        "train_input_part1 = train_df_parts[0] #57 43\n",
        "train_input_part2 = train_df_parts[1] #50 50\n",
        "train_input_part3 = train_df_parts[2] #54 46\n",
        "\n",
        "#printing the length of each part\n",
        "print(\"Length of Part 1:\", len(train_input_part1))\n",
        "print(\"Length of Part 2:\", len(train_input_part2))\n",
        "print(\"Length of Part 3:\", len(train_input_part3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVEB3Yoj2e53",
        "outputId": "dcb92a21-60b9-44ec-f4ac-ee530c4be47a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of Part 1: 30000\n",
            "Length of Part 2: 30000\n",
            "Length of Part 3: 30000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split the dataset into three parts\n",
        "train_output_df_parts = np.array_split(train_output_data, 3)\n",
        "\n",
        "#Assign three different training inputs for their respective operating conditions\n",
        "train_output_part1 = train_output_df_parts[0] #57 43\n",
        "train_output_part2 = train_output_df_parts[1] #50 50\n",
        "train_output_part3 = train_output_df_parts[2] #54 46\n",
        "\n",
        "#Printing the length of each part\n",
        "print(\"Length of Part 1:\", len(train_output_part1))\n",
        "print(\"Length of Part 2:\", len(train_output_part2))\n",
        "print(\"Length of Part 3:\", len(train_output_part3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZad6Yl12hSL",
        "outputId": "e1006588-b83c-4763-f6ca-f557687e9a77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of Part 1: 30000\n",
            "Length of Part 2: 30000\n",
            "Length of Part 3: 30000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split the dataset into three parts\n",
        "test_input_df_parts = np.array_split(test_input_data, 3)\n",
        "\n",
        "#Assign three different training inputs for their respective operating conditions\n",
        "test_intput_part1 = test_input_df_parts[0] #57 43\n",
        "test_intput_part2 = test_input_df_parts[1] #50 50\n",
        "test_intput_part3 = test_input_df_parts[2] #54 46\n",
        "\n",
        "# Printing the length of each part\n",
        "print(\"Length of Part 1:\", len(test_intput_part1))\n",
        "print(\"Length of Part 2:\", len(test_intput_part2))\n",
        "print(\"Length of Part 3:\", len(test_intput_part3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6bn495V2hxG",
        "outputId": "1d28bf70-ef9c-42ae-b164-dc8ae6c593bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of Part 1: 20000\n",
            "Length of Part 2: 20000\n",
            "Length of Part 3: 20000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split the dataset into three parts\n",
        "test_output_df_parts = np.array_split(test_output_data, 3)\n",
        "\n",
        "#Assign three different training inputs for their respective operating conditions\n",
        "test_output_part1 = test_output_df_parts[0] #57 43\n",
        "test_output_part2 = test_output_df_parts[1] #50 50\n",
        "test_output_part3 = test_output_df_parts[2] #54 46\n",
        "\n",
        "# Printing the length of each part\n",
        "print(\"Length of Part 1:\", len(test_output_part1))\n",
        "print(\"Length of Part 2:\", len(test_output_part2))\n",
        "print(\"Length of Part 3:\", len(test_output_part3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gV4B5fgM2jmT",
        "outputId": "60569e78-4ba8-4a4c-c5ac-af21288e900c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of Part 1: 20000\n",
            "Length of Part 2: 20000\n",
            "Length of Part 3: 20000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementaing three different models for three different operating conditions and testing them on corresponding output."
      ],
      "metadata": {
        "id": "snJgF6YJBgm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#For LSTM, first converting the input to numpy array, then reshaping it\n",
        "train_input_data_array = train_input_part1.to_numpy()\n",
        "train_input_data_lstm = train_input_data_array.reshape(train_input_data_array.shape[0], 1, train_input_data_array.shape[1])\n",
        "\n",
        "#Function to return the model 1\n",
        "def get_lstm_model_1(n_inputs, n_outputs):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(64, input_shape=(None, n_inputs), kernel_initializer='he_uniform', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(n_outputs))\n",
        "    return model\n",
        "\n",
        "#Define and compile the LSTM model\n",
        "lstm_model_1 = get_lstm_model_1(train_input_part1.shape[1], train_output_part1.shape[1])\n",
        "optimizer = Adam(learning_rate=0.001)  # Custom learning rate for optimization\n",
        "lstm_model_1.compile(loss='mae', optimizer=optimizer)\n",
        "\n",
        "#Train the LSTM model\n",
        "lstm_model_1.fit(train_input_data_lstm, train_output_part1, verbose=1, epochs=50, validation_split=0.2)\n",
        "\n",
        "\n",
        "# Converting output data to numpy array and reshaping for LSTM\n",
        "test_input_data_array = test_intput_part1.to_numpy()\n",
        "test_input_data_lstm = test_input_data_array.reshape(test_input_data_array.shape[0], 1, test_input_data_array.shape[1])\n",
        "\n",
        "# Evaluate the LSTM model on test data\n",
        "loss = lstm_model_1.evaluate(test_input_data_lstm, test_output_part1)\n",
        "print(\"Test Loss:\", loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AA5Va7G92lIb",
        "outputId": "ade59d52-0264-42ec-e60d-7780b7810918"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "750/750 [==============================] - 4s 3ms/step - loss: 2.7163 - val_loss: 0.2041\n",
            "Epoch 2/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.7156 - val_loss: 0.1360\n",
            "Epoch 3/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.6660 - val_loss: 0.1422\n",
            "Epoch 4/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.6108 - val_loss: 0.2842\n",
            "Epoch 5/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.5466 - val_loss: 0.1702\n",
            "Epoch 6/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.4640 - val_loss: 0.2025\n",
            "Epoch 7/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3635 - val_loss: 0.1045\n",
            "Epoch 8/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2415 - val_loss: 0.1588\n",
            "Epoch 9/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1420 - val_loss: 0.0453\n",
            "Epoch 10/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1226 - val_loss: 0.0495\n",
            "Epoch 11/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1221 - val_loss: 0.0523\n",
            "Epoch 12/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1221 - val_loss: 0.0508\n",
            "Epoch 13/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1220 - val_loss: 0.0507\n",
            "Epoch 14/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1216 - val_loss: 0.0462\n",
            "Epoch 15/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1219 - val_loss: 0.0501\n",
            "Epoch 16/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1220 - val_loss: 0.0546\n",
            "Epoch 17/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1217 - val_loss: 0.0484\n",
            "Epoch 18/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1220 - val_loss: 0.0438\n",
            "Epoch 19/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1214 - val_loss: 0.0572\n",
            "Epoch 20/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1217 - val_loss: 0.0635\n",
            "Epoch 21/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1217 - val_loss: 0.0640\n",
            "Epoch 22/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1216 - val_loss: 0.0509\n",
            "Epoch 23/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1218 - val_loss: 0.0481\n",
            "Epoch 24/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1219 - val_loss: 0.0497\n",
            "Epoch 25/50\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.1219 - val_loss: 0.0471\n",
            "Epoch 26/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1215 - val_loss: 0.0605\n",
            "Epoch 27/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1216 - val_loss: 0.0582\n",
            "Epoch 28/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1217 - val_loss: 0.0538\n",
            "Epoch 29/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1216 - val_loss: 0.0558\n",
            "Epoch 30/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1216 - val_loss: 0.0562\n",
            "Epoch 31/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1216 - val_loss: 0.0562\n",
            "Epoch 32/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1216 - val_loss: 0.0532\n",
            "Epoch 33/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1219 - val_loss: 0.0476\n",
            "Epoch 34/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1216 - val_loss: 0.0670\n",
            "Epoch 35/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1214 - val_loss: 0.0564\n",
            "Epoch 36/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1217 - val_loss: 0.0493\n",
            "Epoch 37/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1217 - val_loss: 0.0565\n",
            "Epoch 38/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1219 - val_loss: 0.0560\n",
            "Epoch 39/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1217 - val_loss: 0.0457\n",
            "Epoch 40/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1216 - val_loss: 0.0590\n",
            "Epoch 41/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1217 - val_loss: 0.0507\n",
            "Epoch 42/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1216 - val_loss: 0.0533\n",
            "Epoch 43/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1216 - val_loss: 0.0521\n",
            "Epoch 44/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1216 - val_loss: 0.0447\n",
            "Epoch 45/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1216 - val_loss: 0.0531\n",
            "Epoch 46/50\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.1216 - val_loss: 0.0534\n",
            "Epoch 47/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1216 - val_loss: 0.0710\n",
            "Epoch 48/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1217 - val_loss: 0.0433\n",
            "Epoch 49/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1216 - val_loss: 0.0512\n",
            "Epoch 50/50\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.1216 - val_loss: 0.0507\n",
            "625/625 [==============================] - 1s 1ms/step - loss: 0.2151\n",
            "Test Loss: 0.21509292721748352\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Test Loss = 0.21509\n",
        "2. As the data is now smaller than the entire dataset, 100 epochs were resulting in overfitting, hence larger loss. Hence reducing it to 50"
      ],
      "metadata": {
        "id": "FSamsVBiB-37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_input_data_array = train_input_part2.to_numpy()\n",
        "train_input_data_lstm = train_input_data_array.reshape(train_input_data_array.shape[0], 1, train_input_data_array.shape[1])\n",
        "\n",
        "def get_lstm_model_2(n_inputs, n_outputs):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(64, input_shape=(None, n_inputs), kernel_initializer='he_uniform', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(n_outputs))\n",
        "    return model\n",
        "\n",
        "\n",
        "# Define and compile the LSTM model\n",
        "lstm_model_2 = get_lstm_model_2(train_input_part2.shape[1], train_output_part2.shape[1])\n",
        "optimizer = Adam(learning_rate=0.001)  # Custom learning rate for optimization\n",
        "lstm_model_2.compile(loss='mae', optimizer=optimizer)\n",
        "\n",
        "# Train the LSTM model\n",
        "lstm_model_2.fit(train_input_data_lstm, train_output_part2, verbose=1, epochs=50, validation_split=0.2)\n",
        "\n",
        "\n",
        "# Convert DataFrame to NumPy array and reshape for LSTM\n",
        "test_input_data_array = test_intput_part2.to_numpy()\n",
        "test_input_data_lstm = test_input_data_array.reshape(test_input_data_array.shape[0], 1, test_input_data_array.shape[1])\n",
        "\n",
        "# Evaluate the LSTM model on test data\n",
        "loss = lstm_model_2.evaluate(test_input_data_lstm, test_output_part2)\n",
        "print(\"\\n\\n\")\n",
        "print(\"Test Loss:\", loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PSPBjqOFx4Y",
        "outputId": "e8282589-0239-4bee-ed3d-fb3bb920b77a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "750/750 [==============================] - 3s 2ms/step - loss: 2.7443 - val_loss: 0.1637\n",
            "Epoch 2/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.7313 - val_loss: 0.1030\n",
            "Epoch 3/50\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.6705 - val_loss: 0.1207\n",
            "Epoch 4/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.6184 - val_loss: 0.1388\n",
            "Epoch 5/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.5466 - val_loss: 0.0965\n",
            "Epoch 6/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.4656 - val_loss: 0.0819\n",
            "Epoch 7/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3625 - val_loss: 0.0692\n",
            "Epoch 8/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2372 - val_loss: 0.0453\n",
            "Epoch 9/50\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.1409 - val_loss: 0.0329\n",
            "Epoch 10/50\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.1238 - val_loss: 0.0298\n",
            "Epoch 11/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1239 - val_loss: 0.0340\n",
            "Epoch 12/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1236 - val_loss: 0.0367\n",
            "Epoch 13/50\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.1235 - val_loss: 0.0298\n",
            "Epoch 14/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1236 - val_loss: 0.0413\n",
            "Epoch 15/50\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.1234 - val_loss: 0.0382\n",
            "Epoch 16/50\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.1238 - val_loss: 0.0315\n",
            "Epoch 17/50\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.1234 - val_loss: 0.0314\n",
            "Epoch 18/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1232 - val_loss: 0.0327\n",
            "Epoch 19/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1234 - val_loss: 0.0328\n",
            "Epoch 20/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1236 - val_loss: 0.0315\n",
            "Epoch 21/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1233 - val_loss: 0.0307\n",
            "Epoch 22/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1234 - val_loss: 0.0350\n",
            "Epoch 23/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1233 - val_loss: 0.0413\n",
            "Epoch 24/50\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.1232 - val_loss: 0.0354\n",
            "Epoch 25/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1233 - val_loss: 0.0369\n",
            "Epoch 26/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1234 - val_loss: 0.0368\n",
            "Epoch 27/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1233 - val_loss: 0.0429\n",
            "Epoch 28/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1232 - val_loss: 0.0365\n",
            "Epoch 29/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1232 - val_loss: 0.0317\n",
            "Epoch 30/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1232 - val_loss: 0.0380\n",
            "Epoch 31/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1233 - val_loss: 0.0460\n",
            "Epoch 32/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1233 - val_loss: 0.0304\n",
            "Epoch 33/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1232 - val_loss: 0.0345\n",
            "Epoch 34/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1233 - val_loss: 0.0376\n",
            "Epoch 35/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1236 - val_loss: 0.0309\n",
            "Epoch 36/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1235 - val_loss: 0.0377\n",
            "Epoch 37/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1231 - val_loss: 0.0379\n",
            "Epoch 38/50\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.1234 - val_loss: 0.0370\n",
            "Epoch 39/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1232 - val_loss: 0.0350\n",
            "Epoch 40/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1234 - val_loss: 0.0333\n",
            "Epoch 41/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1232 - val_loss: 0.0311\n",
            "Epoch 42/50\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.1233 - val_loss: 0.0354\n",
            "Epoch 43/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1233 - val_loss: 0.0421\n",
            "Epoch 44/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1233 - val_loss: 0.0395\n",
            "Epoch 45/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1234 - val_loss: 0.0343\n",
            "Epoch 46/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1235 - val_loss: 0.0297\n",
            "Epoch 47/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1235 - val_loss: 0.0357\n",
            "Epoch 48/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1235 - val_loss: 0.0352\n",
            "Epoch 49/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1235 - val_loss: 0.0344\n",
            "Epoch 50/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1233 - val_loss: 0.0398\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.1893\n",
            "\n",
            "\n",
            "\n",
            "Test Loss: 0.18927642703056335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_input_data_array = train_input_part3.to_numpy()\n",
        "train_input_data_lstm = train_input_data_array.reshape(train_input_data_array.shape[0], 1, train_input_data_array.shape[1])\n",
        "\n",
        "def get_lstm_model_3(n_inputs, n_outputs):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(64, input_shape=(None, n_inputs), kernel_initializer='he_uniform', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(n_outputs))\n",
        "    return model\n",
        "\n",
        "\n",
        "# Define and compile the LSTM model\n",
        "lstm_model_3 = get_lstm_model_3(train_input_part3.shape[1], train_output_part3.shape[1])\n",
        "optimizer = Adam(learning_rate=0.001)  # Custom learning rate for optimization\n",
        "lstm_model_3.compile(loss='mae', optimizer=optimizer)\n",
        "\n",
        "# Train the LSTM model\n",
        "lstm_model_3.fit(train_input_data_lstm, train_output_part3, verbose=1, epochs=50, validation_split=0.2)\n",
        "\n",
        "\n",
        "# Convert DataFrame to NumPy array and reshape for LSTM\n",
        "test_input_data_array = test_intput_part3.to_numpy()\n",
        "test_input_data_lstm = test_input_data_array.reshape(test_input_data_array.shape[0], 1, test_input_data_array.shape[1])\n",
        "\n",
        "# Evaluate the LSTM model on test data\n",
        "loss = lstm_model_3.evaluate(test_input_data_lstm, test_output_part3)\n",
        "print(\"\\n\\n\")\n",
        "print(\"Test Loss:\", loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6utMR42H104",
        "outputId": "37ea6db0-98aa-40ca-8b38-be8dc278a112"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "750/750 [==============================] - 3s 3ms/step - loss: 2.5448 - val_loss: 0.1597\n",
            "Epoch 2/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.7196 - val_loss: 0.1495\n",
            "Epoch 3/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.6478 - val_loss: 0.0976\n",
            "Epoch 4/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.5579 - val_loss: 0.0772\n",
            "Epoch 5/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.4453 - val_loss: 0.0655\n",
            "Epoch 6/50\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3013 - val_loss: 0.0854\n",
            "Epoch 7/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1543 - val_loss: 0.0316\n",
            "Epoch 8/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.0796 - val_loss: 0.0354\n",
            "Epoch 9/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.0770 - val_loss: 0.0418\n",
            "Epoch 10/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.0764 - val_loss: 0.0282\n",
            "Epoch 11/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.0766 - val_loss: 0.0319\n",
            "Epoch 12/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.0765 - val_loss: 0.0357\n",
            "Epoch 13/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.0765 - val_loss: 0.0402\n",
            "Epoch 14/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.0765 - val_loss: 0.0334\n",
            "Epoch 15/50\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.0761 - val_loss: 0.0305\n",
            "Epoch 16/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.0762 - val_loss: 0.0278\n",
            "Epoch 17/50\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.0760 - val_loss: 0.0399\n",
            "Epoch 18/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.0760 - val_loss: 0.0262\n",
            "Epoch 19/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.0759 - val_loss: 0.0439\n",
            "Epoch 20/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.0762 - val_loss: 0.0316\n",
            "Epoch 21/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.0761 - val_loss: 0.0361\n",
            "Epoch 22/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.0759 - val_loss: 0.0372\n",
            "Epoch 23/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.0760 - val_loss: 0.0294\n",
            "Epoch 24/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.0761 - val_loss: 0.0254\n",
            "Epoch 25/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.0762 - val_loss: 0.0268\n",
            "Epoch 26/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.0760 - val_loss: 0.0290\n",
            "Epoch 27/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.0758 - val_loss: 0.0307\n",
            "Epoch 28/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.0761 - val_loss: 0.0276\n",
            "Epoch 29/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.0761 - val_loss: 0.0235\n",
            "Epoch 30/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.0760 - val_loss: 0.0367\n",
            "Epoch 31/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.0760 - val_loss: 0.0289\n",
            "Epoch 32/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.0759 - val_loss: 0.0294\n",
            "Epoch 33/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.0760 - val_loss: 0.0412\n",
            "Epoch 34/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.0761 - val_loss: 0.0284\n",
            "Epoch 35/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.0760 - val_loss: 0.0435\n",
            "Epoch 36/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.0762 - val_loss: 0.0282\n",
            "Epoch 37/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.0761 - val_loss: 0.0338\n",
            "Epoch 38/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.0759 - val_loss: 0.0421\n",
            "Epoch 39/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.0759 - val_loss: 0.0395\n",
            "Epoch 40/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.0762 - val_loss: 0.0309\n",
            "Epoch 41/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.0759 - val_loss: 0.0356\n",
            "Epoch 42/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.0760 - val_loss: 0.0279\n",
            "Epoch 43/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.0760 - val_loss: 0.0298\n",
            "Epoch 44/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.0760 - val_loss: 0.0375\n",
            "Epoch 45/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.0761 - val_loss: 0.0327\n",
            "Epoch 46/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.0760 - val_loss: 0.0343\n",
            "Epoch 47/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.0760 - val_loss: 0.0398\n",
            "Epoch 48/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.0761 - val_loss: 0.0243\n",
            "Epoch 49/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.0759 - val_loss: 0.0270\n",
            "Epoch 50/50\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.0760 - val_loss: 0.0328\n",
            "625/625 [==============================] - 1s 1ms/step - loss: 0.2567\n",
            "\n",
            "\n",
            "\n",
            "Test Loss: 0.2567264437675476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference based on if - else for a simple example:"
      ],
      "metadata": {
        "id": "HrEaJJuzCQ35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using\n",
        "row = [53,47]\n",
        "# we get:\n",
        "# prediction using lstm_model_3\n",
        "# [[15.340948 14.587563]]\n",
        "first_value = row[0]\n",
        "if (54<first_value<57):\n",
        "    # Use model1 for prediction\n",
        "    prediction = lstm_model_1.predict(np.array(row).reshape(1, 1, 2))  # Assuming your model expects input shape (batch_size, time_steps, features)\n",
        "    print(\"prediction using lstm_model_1\")\n",
        "    print(prediction)\n",
        "elif (first_value<=50):\n",
        "    # Use model2 for prediction\n",
        "    prediction = lstm_model_2.predict(np.array(row).reshape(1, 1, 2))  # Assuming your model expects input shape (batch_size, time_steps, features)\n",
        "    print(\"prediction using lstm_model_2\")\n",
        "    print(prediction)\n",
        "elif (50<first_value<=54):\n",
        "    # Use model3 for prediction\n",
        "    prediction = lstm_model_3.predict(np.array(row).reshape(1, 1, 2))  # Assuming your model expects input shape (batch_size, time_steps, features)\n",
        "    print(\"prediction using lstm_model_3\")\n",
        "    print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UL1zTXd6I8EB",
        "outputId": "10697284-86f1-474b-af10-6eaae21e1710"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 156ms/step\n",
            "prediction using lstm_model_3\n",
            "[[15.340948 14.587563]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_input_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4Y_0ZjgLRbj",
        "outputId": "8da2a57b-974a-4812-ca03-a3152357d3b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       v1  v2\n",
            "0      55  45\n",
            "1      55  45\n",
            "2      55  45\n",
            "3      55  45\n",
            "4      55  45\n",
            "...    ..  ..\n",
            "89995  52  48\n",
            "89996  56  44\n",
            "89997  56  44\n",
            "89998  56  44\n",
            "89999  52  48\n",
            "\n",
            "[90000 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the logical inference on random small sample from the original dataset"
      ],
      "metadata": {
        "id": "SaHKbnEHCc5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "final_responses = []\n",
        "output_data = []\n",
        "random_sample = test_input_data.sample(n=100)\n",
        "for index, row in random_sample.iterrows():\n",
        "    #just checking the first value of the operating condition, as the second value is just 100-first value\n",
        "    operating_condition = row['v1']\n",
        "\n",
        "    # Reshape the row to match the input shape expected by the model\n",
        "    input_data = np.array(row.values).reshape(1, 1, -1)\n",
        "    output_data_row = test_output_data.loc[index];\n",
        "    output_data.append(output_data_row)\n",
        "    # Choose the appropriate model based on the operating condition\n",
        "    if (54<operating_condition<=57):\n",
        "        model = lstm_model_1\n",
        "    elif (operating_condition<=50):\n",
        "        model = lstm_model_2\n",
        "    elif(50< operating_condition <= 54):\n",
        "        model = lstm_model_3\n",
        "    else:\n",
        "        # Handle cases where the operating condition does not match any condition\n",
        "        continue\n",
        "\n",
        "    # Make predictions using the selected model\n",
        "    prediction = model.predict(input_data)\n",
        "\n",
        "    # Append the predicted response to the final_responses list\n",
        "    final_responses.append(prediction)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFHd4LhxLrMt",
        "outputId": "b968a06d-8322-46f2-e8d3-0bc168d0e946"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#uncomment this code to print the chosen random sample:\n",
        "#print(random_sample)\n",
        "#printing the predictions:\n",
        "for i in range(len(final_responses)):\n",
        "  print(final_responses[i][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GS7IaLa7GLwb",
        "outputId": "55c48f05-d992-445c-a0ec-a3b328eb1c99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14.6341715 15.285382 ]\n",
            "[15.340948 14.587563]\n",
            "[15.34087  14.587639]\n",
            "[16.361809  13.6784315]\n",
            "[14.634602 15.286359]\n",
            "[14.6341715 15.285382 ]\n",
            "[15.34087  14.587639]\n",
            "[14.6341715 15.285382 ]\n",
            "[15.34087  14.587639]\n",
            "[15.34087  14.587639]\n",
            "[14.634602 15.286359]\n",
            "[15.34087  14.587639]\n",
            "[15.34087  14.587639]\n",
            "[16.361809  13.6784315]\n",
            "[15.34087  14.587639]\n",
            "[16.361809  13.6784315]\n",
            "[16.361809  13.6784315]\n",
            "[16.361809  13.6784315]\n",
            "[16.361809  13.6784315]\n",
            "[15.34087  14.587639]\n",
            "[15.340948 14.587563]\n",
            "[15.34087  14.587639]\n",
            "[15.340948 14.587563]\n",
            "[14.634602 15.286359]\n",
            "[16.361809  13.6784315]\n",
            "[16.361809  13.6784315]\n",
            "[16.361809  13.6784315]\n",
            "[15.340948 14.587563]\n",
            "[16.361809  13.6784315]\n",
            "[15.34087  14.587639]\n",
            "[15.340948 14.587563]\n",
            "[16.361809  13.6784315]\n",
            "[16.361809  13.6784315]\n",
            "[15.340948 14.587563]\n",
            "[15.34087  14.587639]\n",
            "[15.34087  14.587639]\n",
            "[16.361809  13.6784315]\n",
            "[14.6341715 15.285382 ]\n",
            "[15.340948 14.587563]\n",
            "[14.6341715 15.285382 ]\n",
            "[14.6341715 15.285382 ]\n",
            "[15.34087  14.587639]\n",
            "[14.634602 15.286359]\n",
            "[15.340948 14.587563]\n",
            "[15.34087  14.587639]\n",
            "[14.6341715 15.285382 ]\n",
            "[16.361809  13.6784315]\n",
            "[16.361809  13.6784315]\n",
            "[16.361809  13.6784315]\n",
            "[16.361809  13.6784315]\n",
            "[14.634602 15.286359]\n",
            "[14.634602 15.286359]\n",
            "[14.6341715 15.285382 ]\n",
            "[16.361809  13.6784315]\n",
            "[15.340948 14.587563]\n",
            "[15.34087  14.587639]\n",
            "[15.34087  14.587639]\n",
            "[14.6341715 15.285382 ]\n",
            "[16.361809  13.6784315]\n",
            "[15.340948 14.587563]\n",
            "[15.340948 14.587563]\n",
            "[15.340948 14.587563]\n",
            "[15.340948 14.587563]\n",
            "[14.634602 15.286359]\n",
            "[16.361809  13.6784315]\n",
            "[14.634602 15.286359]\n",
            "[14.634602 15.286359]\n",
            "[14.634602 15.286359]\n",
            "[14.6341715 15.285382 ]\n",
            "[14.634602 15.286359]\n",
            "[16.361809  13.6784315]\n",
            "[16.361809  13.6784315]\n",
            "[15.340948 14.587563]\n",
            "[15.340948 14.587563]\n",
            "[14.6341715 15.285382 ]\n",
            "[16.361809  13.6784315]\n",
            "[14.6341715 15.285382 ]\n",
            "[15.340948 14.587563]\n"
          ]
        }
      ]
    }
  ]
}