{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Niranjan Jangir\n",
        "B21CH021"
      ],
      "metadata": {
        "id": "NUlpuzZm7xox"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing necessary libraries:"
      ],
      "metadata": {
        "id": "ibhngrQM75Kq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pn2YeLdUpx19"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.io import loadmat\n",
        "import matplotlib as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading the matlab dataset"
      ],
      "metadata": {
        "id": "Eg0TH60z8oPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = loadmat(r\"Training_Data_Four_Tanks.mat\")\n",
        "testing_data = loadmat(r\"Testing_Data_Four_Tanks.mat\")"
      ],
      "metadata": {
        "id": "68T3uvXsp_rO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading this training and testing MATLAB dataset as pandas dataframe along with extracting it's input, output and time span data separately."
      ],
      "metadata": {
        "id": "_I2xkYd187_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_input_data = pd.DataFrame(training_data['input_data'],columns = ['v1','v2'])  #input features\n",
        "train_output_data = pd.DataFrame(training_data['output_data'],columns =['h1','h2']) #output features\n",
        "train_time_span = pd.DataFrame(training_data['time_span'],columns=['time']) #time span"
      ],
      "metadata": {
        "id": "E7cAjz_FqBHk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_input_data = pd.DataFrame(testing_data['input_data'],columns = ['v1','v2']) #input features\n",
        "test_output_data = pd.DataFrame(testing_data['output_data'],columns =['h1','h2']) #output features\n",
        "test_time_span = pd.DataFrame(testing_data['time_span'],columns=['time']) #time span"
      ],
      "metadata": {
        "id": "UISZvnshqC8A"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use LSTM, we convert the input data to first a numpy array, then reshape this array as below:"
      ],
      "metadata": {
        "id": "g0v5aHQS9Nyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_input_data_array = train_input_data.to_numpy()\n",
        "train_input_data_lstm = train_input_data_array.reshape(train_input_data_array.shape[0], 1, train_input_data_array.shape[1])"
      ],
      "metadata": {
        "id": "UxYBFW1xqHW3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is the implementation of a LSTM model:"
      ],
      "metadata": {
        "id": "JW_kqCJQ9iSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining a function to create the model:\n",
        "def get_lstm_model(n_inputs, n_outputs):\n",
        "    model = Sequential()  # Initialize a Sequential model\n",
        "    model.add(LSTM(64, input_shape=(None, n_inputs), kernel_initializer='he_uniform', activation='relu'))  # Add an LSTM layer with 64 units, ReLU activation, and He uniform weight initialization\n",
        "    model.add(BatchNormalization())  # Add batch normalization layer to stabilize and accelerate the learning process\n",
        "    model.add(Dropout(0.2))  # Add dropout layer to randomly set a fraction of input units to 0 at each update during training to reduce overfitting\n",
        "    model.add(Dense(32, activation='relu'))  # Add a fully connected layer with 32 units and ReLU activation\n",
        "    model.add(Dense(n_outputs))  # Add the output layer\n",
        "    return model  # Return the model\n",
        "\n",
        "# Define and compile the LSTM model on the input training data\n",
        "lstm_model = get_lstm_model(train_input_data.shape[1], train_output_data.shape[1])\n",
        "optimizer = Adam(learning_rate=0.001)  # Custom learning rate for optimization\n",
        "lstm_model.compile(loss='mae', optimizer=optimizer) #compiling the model\n",
        "\n",
        "# Training the LSTM model\n",
        "lstm_model.fit(train_input_data_lstm, train_output_data, verbose=1, epochs=30, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVhCL4MaqO-N",
        "outputId": "e846287d-41ca-4f8b-ee19-8de1c32b8519"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "2250/2250 [==============================] - 13s 5ms/step - loss: 1.5579 - val_loss: 0.4431\n",
            "Epoch 2/30\n",
            "2250/2250 [==============================] - 10s 4ms/step - loss: 0.6456 - val_loss: 0.4640\n",
            "Epoch 3/30\n",
            "2250/2250 [==============================] - 13s 6ms/step - loss: 0.4437 - val_loss: 0.5215\n",
            "Epoch 4/30\n",
            "2250/2250 [==============================] - 11s 5ms/step - loss: 0.2607 - val_loss: 0.5776\n",
            "Epoch 5/30\n",
            "2250/2250 [==============================] - 11s 5ms/step - loss: 0.2156 - val_loss: 0.5663\n",
            "Epoch 6/30\n",
            "2250/2250 [==============================] - 12s 5ms/step - loss: 0.2066 - val_loss: 0.5561\n",
            "Epoch 7/30\n",
            "2250/2250 [==============================] - 10s 5ms/step - loss: 0.2129 - val_loss: 0.5797\n",
            "Epoch 8/30\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 0.2020 - val_loss: 0.5898\n",
            "Epoch 9/30\n",
            "2250/2250 [==============================] - 10s 5ms/step - loss: 0.1975 - val_loss: 0.5506\n",
            "Epoch 10/30\n",
            "2250/2250 [==============================] - 10s 4ms/step - loss: 0.1952 - val_loss: 0.5329\n",
            "Epoch 11/30\n",
            "2250/2250 [==============================] - 10s 4ms/step - loss: 0.1944 - val_loss: 0.5874\n",
            "Epoch 12/30\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 0.1929 - val_loss: 0.5201\n",
            "Epoch 13/30\n",
            "2250/2250 [==============================] - 11s 5ms/step - loss: 0.1919 - val_loss: 0.5084\n",
            "Epoch 14/30\n",
            "2250/2250 [==============================] - 11s 5ms/step - loss: 0.1926 - val_loss: 0.5137\n",
            "Epoch 15/30\n",
            "2250/2250 [==============================] - 10s 4ms/step - loss: 0.1926 - val_loss: 0.5555\n",
            "Epoch 16/30\n",
            "2250/2250 [==============================] - 10s 4ms/step - loss: 0.1917 - val_loss: 0.5695\n",
            "Epoch 17/30\n",
            "2250/2250 [==============================] - 8s 4ms/step - loss: 0.1919 - val_loss: 0.5464\n",
            "Epoch 18/30\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 0.1914 - val_loss: 0.5314\n",
            "Epoch 19/30\n",
            "2250/2250 [==============================] - 8s 3ms/step - loss: 0.1918 - val_loss: 0.5911\n",
            "Epoch 20/30\n",
            "2250/2250 [==============================] - 7s 3ms/step - loss: 0.1917 - val_loss: 0.5070\n",
            "Epoch 21/30\n",
            "2250/2250 [==============================] - 8s 3ms/step - loss: 0.1916 - val_loss: 0.5371\n",
            "Epoch 22/30\n",
            "2250/2250 [==============================] - 7s 3ms/step - loss: 0.1905 - val_loss: 0.5500\n",
            "Epoch 23/30\n",
            "2250/2250 [==============================] - 8s 4ms/step - loss: 0.1908 - val_loss: 0.5147\n",
            "Epoch 24/30\n",
            "2250/2250 [==============================] - 7s 3ms/step - loss: 0.1911 - val_loss: 0.5046\n",
            "Epoch 25/30\n",
            "2250/2250 [==============================] - 7s 3ms/step - loss: 0.1906 - val_loss: 0.5151\n",
            "Epoch 26/30\n",
            "2250/2250 [==============================] - 8s 3ms/step - loss: 0.1901 - val_loss: 0.5041\n",
            "Epoch 27/30\n",
            "2250/2250 [==============================] - 7s 3ms/step - loss: 0.1902 - val_loss: 0.5118\n",
            "Epoch 28/30\n",
            "2250/2250 [==============================] - 8s 3ms/step - loss: 0.1898 - val_loss: 0.5021\n",
            "Epoch 29/30\n",
            "2250/2250 [==============================] - 7s 3ms/step - loss: 0.1897 - val_loss: 0.5211\n",
            "Epoch 30/30\n",
            "2250/2250 [==============================] - 8s 3ms/step - loss: 0.1895 - val_loss: 0.5829\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d976433f5b0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the implementated model on the testing dataset and printing the loss:"
      ],
      "metadata": {
        "id": "x_KE_cX5-CpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data to numpy array and reshape for LSTM\n",
        "test_input_data_array = test_input_data.to_numpy()\n",
        "test_input_data_lstm = test_input_data_array.reshape(test_input_data_array.shape[0], 1, test_input_data_array.shape[1])\n",
        "\n",
        "# Evaluate the LSTM model on test data\n",
        "loss = lstm_model.evaluate(test_input_data_lstm, test_output_data)\n",
        "print(\"Test Loss:\", loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nditytTrtbb0",
        "outputId": "618e86be-76c5-4933-fc81-59c91d47f7c0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1876/1876 [==============================] - 4s 2ms/step - loss: 0.3672\n",
            "Test Loss: 0.3672342300415039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusions:\n",
        "1. LSTM took more time to compile for same number of epochs as compared to RNN due to the increased complexity of LSTM layers, which involve more computations and parameters to train, such as memory cells and gates.\n",
        "2. when epochs = 100 : loss = 0.3439,\n",
        "when epochs = 80 : loss = 0.3011,\n",
        "when epochs = 60 : loss = 0.37\n",
        "3. We can see that with optimal epochs, LSTM has slightly less accuracy than RNN. It may be due to more complexity and more parameters, which can lead to overfitting or difficulty in capturing patterns in the data effectively, resulting in higher loss."
      ],
      "metadata": {
        "id": "FYI_UlNh-rpE"
      }
    }
  ]
}